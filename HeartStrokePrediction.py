# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p1-o_LcTFOg-TrlgLIwMO7xHUKZEVnRC
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.cm import rainbow
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

df=pd.read_csv('dataset.csv')

df.head()

df.describe

df.info()

import seaborn as sns
corrmat=df.corr()
topCorrFeatures=corrmat.index
topCorrFeatures

plt.figure(figsize=(20,20))
topCorrFeatures
g=sns.heatmap(df[topCorrFeatures].corr(),annot=True,cmap="RdYlGn")

sns.countplot(x='target',data=df,palette='RdBu_r')

plt.figure(figsize=(50,50))
df.hist()

ds=pd.get_dummies(df,columns=['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])

ds

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
stdScaler=StandardScaler()
colsToScale= ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
ds[colsToScale]=stdScaler.fit_transform(ds[colsToScale])

ds

y=ds['target']
x=ds.drop(['target'],axis=1)
y

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
knnScores=[]
for k in range(1,21):
  knnClf=KNeighborsClassifier(n_neighbors = k)
  score=cross_val_score(knnClf,x,y,cv=10)
  knnScores.append(score.mean())



plt.figure(figsize=(30,30))
plt.plot([k for k in range(1,21)],knnScores,color='red')
for i in range(1,21):
  plt.text(i, knnScores[i-1], (i, knnScores[i-1]))
plt.xticks([i for i in range(1, 21)])
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Scores')
plt.title('K Neighbors Classifier scores for different K values')

knnClf=KNeighborsClassifier(n_neighbors = 12)
 score=cross_val_score(knnClf,x,y,cv=10)
 score.mean()

randomforest_classifier= RandomForestClassifier(n_estimators=10)

score=cross_val_score(randomforest_classifier,x,y,cv=10)
score.mean()

randomforest_classifier= RandomForestClassifier(n_estimators=10)

score=cross_val_score(randomforest_classifier,x,y,cv=10)
score.mean()

clf=DecisionTreeClassifier(criterion='entropy',max_depth=10)
score=cross_val_score(randomforest_classifier,x,y,cv=10)
score.mean()

randomForestScores=[]
for k in range(1,20):
  clf=DecisionTreeClassifier(criterion='entropy',max_depth=k)
  score=cross_val_score(clf,x,y,cv=10)
  randomForestScores.append(score.mean())

plt.figure(figsize=(30,30))
plt.plot([k for k in range(1,20)],randomForestScores,color='red')
for i in range(1,21):
  plt.text(i, randomForestScores[i-1], (i, randomForestScores[i-1]))
plt.xticks([i for i in range(1, 20)])
plt.xlabel('Maxiumn depth')
plt.ylabel('Scores')
plt.title('Random Forest Classifier scores for different max depth  values')

clf=DecisionTreeClassifier(criterion='entropy',max_depth=10)
score=cross_val_score(randomforest_classifier,x,y,cv=10)
score.mean()